{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.chdir(os.pardir)\n",
    "from models import egnn\n",
    "from builder import build_model, build_dataloader, build_optimizer, build_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[01m[2024-12-16 00:08:44,543] Loading from /p/lustre1/ranganath2/fast.tmp/PDBBIND2020/EGNN-20240819-174309-871564-clrte403/best_model.pth...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import config_util\n",
    "from checkpointer import Checkpointer\n",
    "configs = config_util.load_configs('configs/egnn_denv2_finetune.yml')\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    configs[\"model\"],\n",
    "    configs[\"data\"]\n",
    ")\n",
    "\n",
    "mode = 'test'\n",
    "default_name = 'model'\n",
    "\n",
    "# model.load_state_dict(configs['model']['ckpt_path'])\n",
    "module = model\n",
    "\n",
    "\n",
    "checkpointables = {}\n",
    "optimizer = build_optimizer(\n",
    "                configs[\"train\"][\"optimizer\"], module\n",
    "            )\n",
    "scheduler = build_scheduler(\n",
    "    configs[\"train\"][\"scheduler\"], \n",
    "    optimizer\n",
    ")\n",
    "\n",
    "checkpointer = Checkpointer(\n",
    "    mode, model, '/p/lustre1/ranganath2/fast.tmp/test/', default_name, **checkpointables\n",
    ")\n",
    "\n",
    "checkpointables = {\n",
    "    \"optimizer\": optimizer,\n",
    "    \"scheduler\": scheduler,\n",
    "}\n",
    "\n",
    "checkpoint = checkpointer.resume_or_load(path=configs[\"model\"][\"ckpt_path\"], resume=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[01m[2024-12-16 00:08:48,938] Begin building dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "denv2 = build_dataloader(\n",
    "    configs=configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[01m[2024-12-12 15:48:22,134] Begin building dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pdbbind_configs = config_util.load_configs(\"configs/egcnn_2020.yaml\")\n",
    "pdbbind = build_dataloader(\n",
    "    configs=pdbbind_configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_dataset = pdbbind.get('val')\n",
    "denv2_dataset = denv2.get('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "denv2_batch = next(iter(denv2_dataset))\n",
    "pdb_batch = next(iter(pdbbind_dataset))\n",
    "denv2_batch = [point['data'] for point in denv2_batch]\n",
    "pdb_batch = [point['data'] for point in pdb_batch]\n",
    "loss1 = model(denv2_batch)\n",
    "loss2 = model(pdb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_flat_grad(model):\n",
    "    views = []\n",
    "    for p in model.parameters():\n",
    "        p.retain_grad()\n",
    "        if p.grad is None:\n",
    "            view = p.new(p.numel()).zero_()\n",
    "        elif p.grad.is_sparse:\n",
    "            view = p.grad.to_dense().view(-1)\n",
    "        else:\n",
    "            view = p.grad.view(-1)\n",
    "        views.append(view)\n",
    "    return torch.cat(views, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': tensor(28.6198, grad_fn=<MulBackward0>)}\n",
      "tensor([ 7.9111e-01,  0.0000e+00,  5.8168e-01,  ...,  2.9554e+02,\n",
      "         6.5761e+02, -8.1290e+02])\n"
     ]
    }
   ],
   "source": [
    "print(loss1)\n",
    "model.zero_grad()\n",
    "loss1['mse'].backward()\n",
    "flat_grad = _gather_flat_grad(model)\n",
    "print(flat_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5086.6436)\n"
     ]
    }
   ],
   "source": [
    "print(torch.norm(flat_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': tensor(56.0626, grad_fn=<MulBackward0>)}\n",
      "tensor([ 13.0067,   0.0000,  11.2309,  ..., -40.0471, -89.1088, 110.1522])\n",
      "tensor(1880.5219)\n"
     ]
    }
   ],
   "source": [
    "print(loss2)\n",
    "model.zero_grad()\n",
    "loss2['mse'].backward()\n",
    "flat_grad_2 = _gather_flat_grad(model)\n",
    "print(flat_grad_2)\n",
    "print(torch.norm(flat_grad_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3576)\n"
     ]
    }
   ],
   "source": [
    "print(flat_grad.dot(flat_grad_2)/(flat_grad.norm()* flat_grad_2.norm()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dengue - denv2  denv3  denv4 \n",
    "# pdbbind - x >> 0 proteins\n",
    "# gradient similarity scoring - x \\times denv2 and x \\times denv3 x \\times denv4 (ligands ?) \n",
    "# Tanimoto (SMILES LIGAND SIDE)+ esm3 sequence similarity (Sequence Protein side)\n",
    "\n",
    "\n",
    "# data1 = Extract denv2 - pdbbind similarity with sequences (ESM3)\n",
    "# From data1 data2 = Extract denv2 - pdbbind similar ligands (Tanimoto) \n",
    "\n",
    "# Repeat above with westnile, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
